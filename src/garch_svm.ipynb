{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EGARCH-SVM Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional GARCH models capture volatility clustering but struggle with non-linear market dynamics. Machine learning models like SVR can model complex patterns but lack interpretability. This hybrid GARCH-SVM framework:\n",
    "- Leverages GARCH for parametric volatility estimation\n",
    "- Uses SVR to model residuals and refine forecasts\n",
    "- Combines strengths of both approaches for improved accuracy\n",
    "\n",
    "GARCH provides baseline volatility structure and SVR corrects for GARCH’s limitations in modeling non-linear residuals. Recursive forecasting ensures dynamic updates of both components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>return</th>\n",
       "      <th>RV</th>\n",
       "      <th>lnRV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-23</th>\n",
       "      <td>2.190</td>\n",
       "      <td>2.234</td>\n",
       "      <td>1.800</td>\n",
       "      <td>1.934</td>\n",
       "      <td>-0.125224</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>-3.865058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24</th>\n",
       "      <td>1.932</td>\n",
       "      <td>2.020</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.416</td>\n",
       "      <td>-0.311754</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>-3.652501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close    return        RV      lnRV\n",
       "Date                                                                \n",
       "2019-06-23  2.190  2.234  1.800  1.934 -0.125224  0.020962 -3.865058\n",
       "2019-06-24  1.932  2.020  1.301  1.416 -0.311754  0.025926 -3.652501"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"..\\data\\ALGO_daily.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.rename(columns={'timestamp': 'Date'}, inplace=True)\n",
    "df.set_index('Date', inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size for 1D forecast: 1654 1653\n",
      "Testing Set Size for 1D forecast: 425 424\n",
      "Testing Period for 1D forecast starts on: 2024-01-02\n",
      "Training Set Size for 3D forecast: 1654 1651\n",
      "Testing Set Size for 3D forecast: 425 422\n",
      "Testing Period for 3D forecast starts on: 2024-01-04\n",
      "Training Set Size for 7D forecast: 1654 1647\n",
      "Testing Set Size for 7D forecast: 425 418\n",
      "Testing Period for 7D forecast starts on: 2024-01-08\n",
      "Training Set Size for 30D forecast: 1654 1624\n",
      "Testing Set Size for 30D forecast: 425 395\n",
      "Testing Period for 30D forecast starts on: 2024-01-31\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split \n",
    "dfs = {}\n",
    "for h in [1, 3, 7, 30]:\n",
    "    \n",
    "    df_h = df[['return', 'lnRV']].copy()\n",
    "    df_h.dropna(inplace=True)\n",
    "\n",
    "    # Split the data into training and testing sets by the cutoff date\n",
    "    cutoff_date='2024-01-01'\n",
    "    r_train, r_test = df_h['return'][:cutoff_date], df_h['return'][cutoff_date:]\n",
    "    lnRV_train, lnRV_test = df_h['lnRV'].shift(-h)[:cutoff_date], df_h['lnRV'].shift(-h)[cutoff_date:]\n",
    "    \n",
    "    # Shift the index to match the corrected dates\n",
    "    temp_index = df_h.index[h:len(lnRV_train)] \n",
    "    lnRV_train = lnRV_train[:len(temp_index)]\n",
    "    lnRV_train.index = temp_index\n",
    "\n",
    "    # Shift the index to match the corrected dates\n",
    "    temp_index = lnRV_test.index[h:] \n",
    "    lnRV_test.dropna(inplace=True)\n",
    "    lnRV_test.index = temp_index\n",
    "    \n",
    "    dfs[h] = {'r_train': r_train, 'r_test': r_test, 'lnRV_train': lnRV_train, 'lnRV_test': lnRV_test}\n",
    "    print(f\"Training Set Size for {h}D forecast:\", len(r_train), len(lnRV_train))\n",
    "    print(f\"Testing Set Size for {h}D forecast:\", len(r_test), len(lnRV_test))\n",
    "    print(f\"Testing Period for {h}D forecast starts on:\", lnRV_test.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(log_returns, log_RV, h=1):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    log_returns (array-like): Daily log return series r₁,..rₙ for the asset\n",
    "    log_RV (array-like): Daily log realized volatility series lnRV₁,..lnRVₙ\n",
    "    h (int): Forecast horizon (number of days ahead to predict)\n",
    "    \n",
    "    Returns:\n",
    "     \n",
    "    \"\"\"\n",
    "    # Step 1: Estimate GARCH parameters\n",
    "    garch_model = arch_model(log_returns, vol='Garch', p=1, q=1, rescale=False)\n",
    "    garch_results = garch_model.fit(disp='off')\n",
    "    \n",
    "    # Step 2: Compute conditional variances σ²₁,..,σ²ₙ\n",
    "    conditional_variances = garch_results.conditional_volatility**2\n",
    "\n",
    "    # Step 3: Compute Mₜ = lnRVₜ - ln(σ²ₜ)\n",
    "    # Note: ln(σ²ₜ) is the log of the conditional variance\n",
    "    L_sequence = np.log(conditional_variances)\n",
    "    print(\"L_sequence size:\", len(L_sequence))\n",
    "    M_sequence = log_RV - L_sequence\n",
    "    print(\"M_sequence size:\", len(M_sequence))\n",
    "    print(\"logRV_sequence size:\", len(log_RV))\n",
    "    \n",
    "    # Step 4: Train SVR model\n",
    "    # Prepare initial data matrix for SVR training\n",
    "    X = np.column_stack([\n",
    "        L_sequence[:-1],            # ln(σ²ₜ₋₁)\n",
    "        M_sequence[:-1],            # Mₜ₋₁\n",
    "        log_RV[:-1]                 # lnRVₜ₋₁\n",
    "    ])\n",
    "    y = M_sequence[1:]              # Mₜ (target)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize and fit SVR model\n",
    "    svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "    svr_model.fit(X_scaled, y)\n",
    "    \n",
    "    # Initialize forecast arrays\n",
    "    L_forecasts = np.zeros(h)\n",
    "    M_forecasts = np.zeros(h)\n",
    "    lnRV_forecasts = np.zeros(h)\n",
    "    \n",
    "    # Initialize the most recent data point\n",
    "    last_L = L_sequence.iloc[-1]\n",
    "    last_M = M_sequence.iloc[-1]\n",
    "    last_lnRV = log_RV.iloc[-1]\n",
    "    \n",
    "    # Recursive forecasting for h steps\n",
    "    for i in range(1, h+1):\n",
    "        # Prepare input for current step\n",
    "        current_X = np.array([last_L, last_M, last_lnRV]).reshape(1, -1)\n",
    "        current_X_scaled = scaler.transform(current_X)\n",
    "        \n",
    "        # Step 5: Forecast M_{t+i}\n",
    "        M_forecast = svr_model.predict(current_X_scaled)[0]\n",
    "        M_forecasts[i-1] = M_forecast\n",
    "        \n",
    "        # Step 6: Forecast σ²_{t+i} using GARCH (1-step ahead each iteration)\n",
    "        sigma_forecast = garch_results.forecast(horizon=1).variance.values[-1, -1]\n",
    "        \n",
    "        # Step 7: Compute lnRVₜ = M_{t+i} + ln(σ²_{t+i})\n",
    "        L_forecast = np.log(sigma_forecast)\n",
    "        L_forecasts[i-1] = L_forecast\n",
    "        lnRV_forecast = M_forecast + L_forecast\n",
    "        lnRV_forecasts[i-1] = lnRV_forecast\n",
    "        \n",
    "        # Update inputs for next step (using forecasts as inputs)\n",
    "        last_L = L_forecast\n",
    "        last_M = M_forecast\n",
    "        last_lnRV = lnRV_forecast\n",
    "        \n",
    "    return lnRV_forecasts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(h):\n",
    "\n",
    "    pred = []\n",
    "    \n",
    "    r_train, r_test = dfs[h]['r_train'], dfs[h]['r_test']\n",
    "    lnRV_train, lnRV_test = dfs[h]['lnRV_train'], dfs[h]['lnRV_test']\n",
    "    \n",
    "    for i in range(len(lnRV_test)):\n",
    "        log_returns = pd.concat([r_train, r_test[:i]])\n",
    "        log_RVs = pd.concat([lnRV_train, lnRV_test[:i]])\n",
    "        forecast = predict(log_returns, log_RVs, h)\n",
    "        pred.append(forecast)\n",
    "    pred = pd.DataFrame(pred, index = lnRV_test.index, columns=['Predicted'])\n",
    "    pred.to_csv(f'../res/GARCH-SVM_{h}D.csv')\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(pred, actual, h):\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(actual, label='Actual')\n",
    "    plt.plot(pred, label='Predicted')\n",
    "    plt.xticks(actual.index[::100])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.title(f'GARCH-SVM_{h}D-Ahead Forecast')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'../res/GARCH-SVM_{h}D-Ahead Forecast.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sequence size: 1654\n",
      "M_sequence size: 1654\n",
      "logRV_sequence size: 1653\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1653 and the array at index 2 has size 1652",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m30\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mget_pred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     plot_pred(pred, dfs[h][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlnRV_test\u001b[39m\u001b[38;5;124m'\u001b[39m], h)\n",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m, in \u001b[0;36mget_pred\u001b[1;34m(h)\u001b[0m\n\u001b[0;32m      9\u001b[0m     log_returns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([r_train, r_test[:i]])\n\u001b[0;32m     10\u001b[0m     log_RVs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([lnRV_train, lnRV_test[:i]])\n\u001b[1;32m---> 11\u001b[0m     forecast \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_returns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_RVs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     pred\u001b[38;5;241m.\u001b[39mappend(forecast)\n\u001b[0;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(pred, index \u001b[38;5;241m=\u001b[39m r_test\u001b[38;5;241m.\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[39], line 28\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(log_returns, log_RV, h)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogRV_sequence size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(log_RV))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Step 4: Train SVR model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Prepare initial data matrix for SVR training\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mL_sequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# ln(σ²ₜ₋₁)\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM_sequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Mₜ₋₁\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_RV\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# lnRVₜ₋₁\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m y \u001b[38;5;241m=\u001b[39m M_sequence[\u001b[38;5;241m1\u001b[39m:]              \u001b[38;5;66;03m# Mₜ (target)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Standardize features\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\65835\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\shape_base.py:656\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    654\u001b[0m         arr \u001b[38;5;241m=\u001b[39m array(arr, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    655\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[1;32m--> 656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1653 and the array at index 2 has size 1652"
     ]
    }
   ],
   "source": [
    "for h in [1,3,7,30]:\n",
    "    pred = get_pred(h)\n",
    "    plot_pred(pred, dfs[h]['lnRV_test'], h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
