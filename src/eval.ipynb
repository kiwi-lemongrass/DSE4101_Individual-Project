{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models are compared based on their forecast performannce on the period from 2024-01-23 to 2025-02-28. (including two ends)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forecast Error Metrics (MAE, RMSE, MASE)\n",
    "\n",
    "- Diebold-Mariano Test (for forecast superiority)\n",
    "\n",
    "- Visual Comparison (actual vs. predicted volatility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the considerations was choosing a recursive estimation scheme over a rolling scheme in forecast estimation. While the latter is better suited for purposes like forecast comparison using DM test (which assumes that the differential is covariance stationary), the recursive estimation scheme is still favoured for practical reasons. This is because by expanding the training set timeframe, it uses more and more data to make later forecasts - parameter uncertainty is reduced, and forecast error may become less variable. Also, parameter estimation uncertainty typically constitutes a tiny fraction of forecast error variance, so reducing it would not noticeably violate stationarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diebold Mariano (1995) EPA Test\n",
    "def diebold_mariano(actual, forecast1, forecast2, h=3):\n",
    "    \"\"\"\n",
    "    DM test for h-step-ahead forecasts.\n",
    "    H0: Forecasts have equal accuracy.\n",
    "    HA: Forecast 1 is more accurate than Forecast 2.\n",
    "    \"\"\"\n",
    "    # Forecast errors\n",
    "    e1 = actual - forecast1\n",
    "    e2 = actual - forecast2\n",
    "    \n",
    "    # Loss differential (squared errors)\n",
    "    d = e1**2 - e2**2\n",
    "    \n",
    "    # DM statistic (with Newey-West adjustment for autocorrelation)\n",
    "    n = len(d)\n",
    "    d_mean = np.mean(d)\n",
    "    d_var = np.var(d, ddof=1)  # HAC adjustment not shown here (see next section)\n",
    "    dm_stat = d_mean / np.sqrt(d_var / n)\n",
    "    \n",
    "    # Critical value (standard normal for large n)\n",
    "    p_value = 2 * norm.sf(np.abs(dm_stat))  # Two-tailed test\n",
    "    \n",
    "    return dm_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\65835\\AppData\\Local\\Temp\\ipykernel_15136\\1011208853.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>1D</th>\n",
       "      <th>3D</th>\n",
       "      <th>7D</th>\n",
       "      <th>30D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GARCH(1,0,1)</td>\n",
       "      <td>MAE</td>\n",
       "      <td>0.464673</td>\n",
       "      <td>0.499103</td>\n",
       "      <td>0.585017</td>\n",
       "      <td>0.883290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GARCH(1,0,1)</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.618827</td>\n",
       "      <td>0.652981</td>\n",
       "      <td>0.727710</td>\n",
       "      <td>1.018471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GARCH(1,0,1)</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>8.344001</td>\n",
       "      <td>8.823486</td>\n",
       "      <td>10.148567</td>\n",
       "      <td>14.930754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GARCH(1,0,1)</td>\n",
       "      <td>R-squared</td>\n",
       "      <td>0.426290</td>\n",
       "      <td>0.349858</td>\n",
       "      <td>0.198842</td>\n",
       "      <td>-0.539389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GARCH-SVM</td>\n",
       "      <td>MAE</td>\n",
       "      <td>0.405708</td>\n",
       "      <td>0.393386</td>\n",
       "      <td>0.487733</td>\n",
       "      <td>0.592328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GARCH-SVM</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.567377</td>\n",
       "      <td>0.542832</td>\n",
       "      <td>0.649414</td>\n",
       "      <td>0.795584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GARCH-SVM</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>7.445700</td>\n",
       "      <td>7.153618</td>\n",
       "      <td>8.795893</td>\n",
       "      <td>10.803316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GARCH-SVM</td>\n",
       "      <td>R-squared</td>\n",
       "      <td>0.517722</td>\n",
       "      <td>0.550698</td>\n",
       "      <td>0.361964</td>\n",
       "      <td>0.060660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model     Metric        1D        3D         7D        30D\n",
       "0  GARCH(1,0,1)        MAE  0.464673  0.499103   0.585017   0.883290\n",
       "1  GARCH(1,0,1)       RMSE  0.618827  0.652981   0.727710   1.018471\n",
       "2  GARCH(1,0,1)       MAPE  8.344001  8.823486  10.148567  14.930754\n",
       "3  GARCH(1,0,1)  R-squared  0.426290  0.349858   0.198842  -0.539389\n",
       "4     GARCH-SVM        MAE  0.405708  0.393386   0.487733   0.592328\n",
       "5     GARCH-SVM       RMSE  0.567377  0.542832   0.649414   0.795584\n",
       "6     GARCH-SVM       MAPE  7.445700  7.153618   8.795893  10.803316\n",
       "7     GARCH-SVM  R-squared  0.517722  0.550698   0.361964   0.060660"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Model', 'Metric', '1D', '3D', '7D', '30D'])\n",
    "\n",
    "for model in ['GARCH(1,0,1)', 'GARCH-SVM']:\n",
    "    maes = []\n",
    "    rmses = []\n",
    "    mapes = []\n",
    "    r2s = []\n",
    "\n",
    "    for h in [1, 3, 7, 30]:\n",
    "        # Load the predictions\n",
    "        predictions = pd.read_csv(f'../res/{model}_{h}D.csv')['Predicted']\n",
    "        actual = pd.read_csv(f'../res/lnRV_test_{h}D.csv')['lnRV']\n",
    "        \n",
    "        # Calculate metrics and append to lists\n",
    "        mae = mean_absolute_error(actual, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "        mape = mean_absolute_percentage_error(actual, predictions) * 100\n",
    "        r2 = r2_score(actual, predictions)\n",
    "\n",
    "        maes.append(mae)\n",
    "        rmses.append(rmse)\n",
    "        mapes.append(mape)\n",
    "        r2s.append(r2)\n",
    "\n",
    "    # Append results to DataFrame\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        'Model': [model] * 4,\n",
    "        'Metric': ['MAE', 'RMSE', 'MAPE', 'R-squared'],\n",
    "        '1D': [maes[0], rmses[0], mapes[0], r2s[0]],\n",
    "        '3D': [maes[1], rmses[1], mapes[1], r2s[1]],\n",
    "        '7D': [maes[2], rmses[2], mapes[2], r2s[2]],\n",
    "        '30D': [maes[3], rmses[3], mapes[3], r2s[3]],\n",
    "    })], ignore_index=True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes = []\n",
    "rmses = []\n",
    "mapes = []\n",
    "r2s = []\n",
    "\n",
    "for h in [1, 3, 7, 30]:\n",
    "    # Load the predictions\n",
    "    predictions = pd.read_csv(f'../res/'HAR(1, 7, 30)'_{h}D.csv')['Pred']\n",
    "    actual = pd.read_csv(f'../res/lnRV_test_{h}D.csv')['lnRV']\n",
    "    \n",
    "    # Calculate metrics and append to lists\n",
    "    mae = mean_absolute_error(actual, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predictions))\n",
    "    mape = mean_absolute_percentage_error(actual, predictions) * 100\n",
    "    r2 = r2_score(actual, predictions)\n",
    "\n",
    "    maes.append(mae)\n",
    "    rmses.append(rmse)\n",
    "    mapes.append(mape)\n",
    "    r2s.append(r2)\n",
    "\n",
    "# Append results to DataFrame\n",
    "results = pd.concat([results, pd.DataFrame({\n",
    "    'Model': [model] * 4,\n",
    "    'Metric': ['MAE', 'RMSE', 'MAPE', 'R-squared'],\n",
    "    '1D': [maes[0], rmses[0], mapes[0], r2s[0]],\n",
    "    '3D': [maes[1], rmses[1], mapes[1], r2s[1]],\n",
    "    '7D': [maes[2], rmses[2], mapes[2], r2s[2]],\n",
    "    '30D': [maes[3], rmses[3], mapes[3], r2s[3]],\n",
    "})], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in [1,3,7,30]:\n",
    "    # load data\n",
    "    garch = pd.read_csv(f'../res/GARCH(1,0,1)_{h}D.csv')['Predicted']\n",
    "    har = pd.read_csv(f'../res/HAR(1, 7, 30)_{h}D.csv')['Pred']\n",
    "    garch_svm = pd.read_csv(f'../res/GARCH-SVM_{h}D.csv')['Predicted']\n",
    "    actual = pd.read_csv(f'../res/lnRV_test_{h}D.csv')['lnRV']\n",
    "\n",
    "    # Mean Absolute Error (MASE)\n",
    "    mae_garch = mean_absolute_error(actual, garch)\n",
    "    mae_har = mean_absolute_error(actual, har)\n",
    "    mae_garch_svm = mean_absolute_error(actual, garch_svm)\n",
    "\n",
    "    # Mean Absolute Error (MASE)\n",
    "    mae_garch = mean_absolute_error(actual, garch)\n",
    "    mae_har = mean_absolute_error(actual, har)\n",
    "    mae_garch_svm = mean_absolute_error(actual, garch_svm)\n",
    "\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse_garch = np.sqrt(mean_squared_error(actual, garch))\n",
    "    rmse_har = np.sqrt(mean_squared_error(actual, har))\n",
    "    rmse_garch_svm = np.sqrt(mean_squared_error(actual, garch_svm))\n",
    "\n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    mape_garch = mean_absolute_percentage_error(actual, garch) * 100\n",
    "    mape_har = mean_absolute_percentage_error(actual, har) * 100\n",
    "    mape_garch_svm = mean_absolute_percentage_error(actual, garch_svm) * 100\n",
    "\n",
    "    # Mean Absolute Scaled Error (MASE) - Lagged realized vol as benchmark\n",
    "    naive_forecast = np.roll(actual, h)\n",
    "    naive_forecast[:h] = np.nan  # Set the first h values to NaN\n",
    "    mase_garch = mean_absolute_error(actual[h:], garch[h:]) / mean_absolute_error(actual[h:], naive_forecast[h:])\n",
    "    mase_har = mean_absolute_error(actual[h:], har[h:]) / mean_absolute_error(actual[h:], naive_forecast[h:])\n",
    "    mase_garch_svm = mean_absolute_error(actual[h:], garch_svm[h:]) / mean_absolute_error(actual[h:], naive_forecast[h:])\n",
    "\n",
    "    # R-squared\n",
    "    r2_garch = r2_score(actual, garch)\n",
    "    r2_har = r2_score(actual, har)\n",
    "    r2_garch_svm = r2_score(actual, garch_svm)\n",
    "\n",
    "    # Diebold-Mariano test\n",
    "    dm_stat_garch_har, p_value_garch_har = diebold_mariano(actual, garch, har)\n",
    "    dm_stat_garch_svm, p_value_garch_svm = diebold_mariano(actual, garch, garch_svm)\n",
    "    dm_stat_har_svm, p_value_har_svm = diebold_mariano(actual, har, garch_svm)\n",
    "\n",
    "    # save results to csv\n",
    "    results = pd.DataFrame({\n",
    "        'Metric': ['MAE', 'RMSE', 'MAPE', 'MASE', 'R-squared'],\n",
    "        'GARCH': [mae_garch, rmse_garch, mape_garch, mase_garch, r2_garch],\n",
    "        'HAR': [mae_har, rmse_har, mape_har, mase_har, r2_har],\n",
    "        'GARCH-SVM': [mae_garch_svm, rmse_garch_svm, mape_garch_svm, mase_garch_svm, r2_garch_svm],\n",
    "    })\n",
    "    results.to_csv(f'../eval/metrics_{h}D.csv', index=False)\n",
    "\n",
    "    # save DM test results to csv\n",
    "    dm_results = pd.DataFrame({\n",
    "        'Comparison': ['GARCH vs HAR', 'GARCH vs GARCH-SVM', 'HAR vs GARCH-SVM'],\n",
    "        'DM Statistic': [dm_stat_garch_har, dm_stat_garch_svm, dm_stat_har_svm],\n",
    "        'p-value': [p_value_garch_har, p_value_garch_svm, p_value_har_svm]\n",
    "    })\n",
    "    dm_results.to_csv(f'../eval/DM_test_{h}D.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for GARCH, HAR, and GARCH-SVM models:\n",
      "------------------------------------------------\n",
      "MAE:\n",
      "GARCH: 0.8833, HAR: 0.3848, GARCH-SVM: 0.5923\n",
      "RMSE:\n",
      "GARCH: 1.0185, HAR: 0.5304, GARCH-SVM: 0.7956\n",
      "MAPE:\n",
      "GARCH: 14.9308%, HAR: 6.9800%, GARCH-SVM: 10.8033%\n",
      "MASE:\n",
      "GARCH: 1.0312, HAR: 0.4703, GARCH-SVM: 0.6903\n",
      "R-squared:\n",
      "GARCH: -0.5394, HAR: 0.5825, GARCH-SVM: 0.0607\n",
      "\n",
      "Diebold-Mariano Test Results:\n",
      "------------------------------------------------\n",
      "GARCH vs HAR: DM Statistic = 13.4567, p-value = 0.0000\n",
      "GARCH vs GARCH-SVM: DM Statistic = 7.6188, p-value = 0.0000\n",
      "HAR vs GARCH-SVM: DM Statistic = -7.7838, p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(\"Metrics for GARCH, HAR, and GARCH-SVM models:\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"MAE:\")\n",
    "print(f\"GARCH: {mae_garch:.4f}, HAR: {mae_har:.4f}, GARCH-SVM: {mae_garch_svm:.4f}\")\n",
    "print(\"RMSE:\")\n",
    "print(f\"GARCH: {rmse_garch:.4f}, HAR: {rmse_har:.4f}, GARCH-SVM: {rmse_garch_svm:.4f}\")\n",
    "print(\"MAPE:\")\n",
    "print(f\"GARCH: {mape_garch:.4f}%, HAR: {mape_har:.4f}%, GARCH-SVM: {mape_garch_svm:.4f}%\")\n",
    "print(\"MASE:\")\n",
    "print(f\"GARCH: {mase_garch:.4f}, HAR: {mase_har:.4f}, GARCH-SVM: {mase_garch_svm:.4f}\")\n",
    "print(\"R-squared:\")\n",
    "print(f\"GARCH: {r2_garch:.4f}, HAR: {r2_har:.4f}, GARCH-SVM: {r2_garch_svm:.4f}\")\n",
    "print(\"\\nDiebold-Mariano Test Results:\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"GARCH vs HAR: DM Statistic = {dm_stat_garch_har:.4f}, p-value = {p_value_garch_har:.4f}\")\n",
    "print(f\"GARCH vs GARCH-SVM: DM Statistic = {dm_stat_garch_svm:.4f}, p-value = {p_value_garch_svm:.4f}\")\n",
    "print(f\"HAR vs GARCH-SVM: DM Statistic = {dm_stat_har_svm:.4f}, p-value = {p_value_har_svm:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
