{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR-SVM Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>return</th>\n",
       "      <th>RV</th>\n",
       "      <th>lnRV</th>\n",
       "      <th>lnRV_1D_ahead</th>\n",
       "      <th>lnRV_3D_ahead</th>\n",
       "      <th>lnRV_7D_ahead</th>\n",
       "      <th>lnRV_30D_ahead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-23</th>\n",
       "      <td>2.190</td>\n",
       "      <td>2.234</td>\n",
       "      <td>1.800</td>\n",
       "      <td>1.934</td>\n",
       "      <td>-0.125224</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>-3.865058</td>\n",
       "      <td>-3.652501</td>\n",
       "      <td>-3.331801</td>\n",
       "      <td>-4.888673</td>\n",
       "      <td>-4.531543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24</th>\n",
       "      <td>1.932</td>\n",
       "      <td>2.020</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.416</td>\n",
       "      <td>-0.311754</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>-3.652501</td>\n",
       "      <td>-3.161881</td>\n",
       "      <td>-3.956779</td>\n",
       "      <td>-4.830684</td>\n",
       "      <td>-4.813612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close    return        RV      lnRV  \\\n",
       "Date                                                                   \n",
       "2019-06-23  2.190  2.234  1.800  1.934 -0.125224  0.020962 -3.865058   \n",
       "2019-06-24  1.932  2.020  1.301  1.416 -0.311754  0.025926 -3.652501   \n",
       "\n",
       "            lnRV_1D_ahead  lnRV_3D_ahead  lnRV_7D_ahead  lnRV_30D_ahead  \n",
       "Date                                                                     \n",
       "2019-06-23      -3.652501      -3.331801      -4.888673       -4.531543  \n",
       "2019-06-24      -3.161881      -3.956779      -4.830684       -4.813612  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"..\\data\\ALGO_daily.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.rename(columns={'timestamp': 'Date'}, inplace=True)\n",
    "df.set_index('Date', inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Size for 1D forecast: 424\n",
      "Testing Set Size for 3D forecast: 422\n",
      "Testing Set Size for 7D forecast: 418\n",
      "Testing Set Size for 30D forecast: 395\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "dfs = {}\n",
    "for h in [1, 3, 7, 30]:\n",
    "    \n",
    "    df_h = df[['return', ''f'lnRV_{h}D_ahead']].copy()\n",
    "    df_h.dropna(inplace=True) \n",
    "\n",
    "    # Split the data into training and testing sets by the cutoff date\n",
    "    cutoff_date='2024-01-01'\n",
    "    r_train, r_test = df_h['return'][:cutoff_date], df_h['return'][cutoff_date:]\n",
    "    lnRV_train, lnRV_test = df_h[f'lnRV_{h}D_ahead'][:cutoff_date], df_h[f'lnRV_{h}D_ahead'][cutoff_date:]\n",
    "    test_size = len(r_test)  \n",
    "    dfs[h] = {'r_train': r_train, 'r_test': r_test, 'lnRV_train': lnRV_train, 'lnRV_test': lnRV_test}\n",
    "    dfs[h] = {'r_train': r_train, 'r_test': r_test, 'lnRV_test': lnRV_test}\n",
    "    print(f\"Testing Set Size for {h}D forecast:\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(log_returns, log_RV, h=1):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    log_returns (array-like): Daily log return series r₁,..rₙ for the asset\n",
    "    log_RV (array-like): Daily log realized volatility series lnRV₁,..lnRVₙ\n",
    "    h (int): Forecast horizon (number of days ahead to predict)\n",
    "    \n",
    "    Returns:\n",
    "     \n",
    "    \"\"\"\n",
    "    # Step 1: Estimate GARCH parameters\n",
    "    garch_model = arch_model(log_returns, vol='Garch', p=1, q=1, rescale=False)\n",
    "    garch_results = garch_model.fit(disp='off')\n",
    "    \n",
    "    # Step 2: Compute conditional variances σ²₁,..,σ²ₙ\n",
    "    conditional_variances = garch_results.conditional_volatility**2\n",
    "\n",
    "    # Step 3: Compute Mₜ = lnRVₜ - ln(σ²ₜ)\n",
    "    # Note: ln(σ²ₜ) is the log of the conditional variance\n",
    "    L_sequence = np.log(conditional_variances)\n",
    "    M_sequence = log_RV - L_sequence\n",
    "    \n",
    "    # Step 4: Train RF model\n",
    "    \n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize and fit SVR model\n",
    "    svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "    svr_model.fit(X_scaled, y)\n",
    "    \n",
    "    # Initialize forecast arrays\n",
    "    L_forecasts = np.zeros(h)\n",
    "    M_forecasts = np.zeros(h)\n",
    "    lnRV_forecasts = np.zeros(h)\n",
    "    \n",
    "    # Initialize the most recent data point\n",
    "    last_L = L_sequence.iloc[-1]\n",
    "    last_M = M_sequence.iloc[-1]\n",
    "    last_lnRV = log_RV.iloc[-1]\n",
    "    \n",
    "    # Recursive forecasting for h steps\n",
    "    for i in range(1, h+1):\n",
    "        # Prepare input for current step\n",
    "        current_X = np.array([last_L, last_M, last_lnRV]).reshape(1, -1)\n",
    "        current_X_scaled = scaler.transform(current_X)\n",
    "        \n",
    "        # Step 5: Forecast M_{t+i}\n",
    "        M_forecast = svr_model.predict(current_X_scaled)[0]\n",
    "        M_forecasts[i-1] = M_forecast\n",
    "        \n",
    "        # Step 6: Forecast σ²_{t+i} using GARCH (1-step ahead each iteration)\n",
    "        sigma_forecast = garch_results.forecast(horizon=1).variance.values[-1, -1]\n",
    "        \n",
    "        # Step 7: Compute lnRVₜ = M_{t+i} + ln(σ²_{t+i})\n",
    "        L_forecast = np.log(sigma_forecast)\n",
    "        L_forecasts[i-1] = L_forecast\n",
    "        lnRV_forecast = M_forecast + L_forecast\n",
    "        lnRV_forecasts[i-1] = lnRV_forecast\n",
    "        \n",
    "        # Update inputs for next step (using forecasts as inputs)\n",
    "        last_L = L_forecast\n",
    "        last_M = M_forecast\n",
    "        last_lnRV = lnRV_forecast\n",
    "        \n",
    "    return lnRV_forecasts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(h):\n",
    "\n",
    "    pred = []\n",
    "    \n",
    "    r_train, r_test = dfs[h]['r_train'], dfs[h]['r_test']\n",
    "    lnRV_train, lnRV_test = dfs[h]['lnRV_train'], dfs[h]['lnRV_test']\n",
    "    \n",
    "    for i in range(len(r_test)):\n",
    "        log_returns = pd.concat([r_train, r_test[:i]])\n",
    "        log_RVs = pd.concat([lnRV_train, lnRV_test[:i]])\n",
    "        forecast = predict(log_returns, log_RVs, h)\n",
    "        pred.append(forecast)\n",
    "    pred = pd.DataFrame(pred, index = r_test.index, columns=['Predicted'])\n",
    "    pred.to_csv(f'../res/GARCH-SVM_{h}D.csv')\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(pred, actual, h):\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(actual, label='Actual')\n",
    "    plt.plot(pred, label='Predicted')\n",
    "    plt.xticks(actual.index[::100])\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.title(f'GARCH-SVM_{h}D-Ahead Forecast')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'../res/GARCH-SVM_{h}D-Ahead Forecast.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lnRV_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m30\u001b[39m]:\n\u001b[1;32m----> 2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mget_pred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     plot_pred(pred, dfs[h][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlnRV_test\u001b[39m\u001b[38;5;124m'\u001b[39m], h)\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mget_pred\u001b[1;34m(h)\u001b[0m\n\u001b[0;32m      3\u001b[0m pred \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m r_train, r_test \u001b[38;5;241m=\u001b[39m dfs[h][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_train\u001b[39m\u001b[38;5;124m'\u001b[39m], dfs[h][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m lnRV_train, lnRV_test \u001b[38;5;241m=\u001b[39m \u001b[43mdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlnRV_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, dfs[h][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlnRV_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(r_test)):\n\u001b[0;32m      9\u001b[0m     log_returns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([r_train, r_test[:i]])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lnRV_train'"
     ]
    }
   ],
   "source": [
    "for h in [1,3,7,30]:\n",
    "    pred = get_pred(h)\n",
    "    plot_pred(pred, dfs[h]['lnRV_test'], h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
